# Benchmarks

- ICCV-W 2025: benchmark on multi-modal, multi-page, and **multi-document** understanding with over 3,000 PDF documents with more than 40,000 pages [M3DocVQA](https://openaccess.thecvf.com/content/ICCV2025W/Findings/html/Cho_M3DocVQA_Multi-modal_Multi-page_Multi-document_Understanding_ICCVW_2025_paper.html)

- EMNLP 2023: first benchmark on object hallucination of LVLMs: [POPE](https://arxiv.org/abs/2305.10355)

- ACL 2023: the first multimodal instruction tuning benchmark dataset that consists of 62 diverse multimodal tasks covering 10 broad categories: [MultiInstruct](https://arxiv.org/pdf/2212.10773)

