# Awesome VLMs

a structured awesome list of VLMs with my notes.

## General surveys

- [ ] ["Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions"](https://arxiv.org/abs/2404.07214) by Ghosh et al. 2024
  - Vision-Language Understanding
  - Text Generation with Multimodal Input
  - Multimodal Output with Multimodal Input
- [ ]

## Model zoo - Vision-Language Understanding

- [x] [CLIP](https://arxiv.org/abs/2103.00020)
- [ ] [AlphaCLIP](https://arxiv.org/abs/2312.03818)
  - motivation: focusing on the regions of interest matters for fine-grained understanding
  - contribution: 
    - datasets with more fine-grained region-text pairs
    - image encoder with an additional alpha channel
    - ![alt text](figures/AlphaCLIP.png)

- [ ] GLIP